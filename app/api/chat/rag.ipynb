{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "#### Install libraries",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "! pip install -q langchain langchain-community openai tiktoken pinecone-client langchain_pinecone unstructured pdfminer==20191125 pdfminer.six==20221105 pillow_heif unstructured_inference youtube-transcript-api pytube sentence-transformers dotenv",
   "id": "ae00c271191dd7ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, WebBaseLoader, YoutubeLoader, DirectoryLoader, TextLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import os\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader"
   ],
   "id": "2b2a823347596371",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Env. Variables\n",
    "load_dotenv()\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "id": "8fdcc19c8dd3d27a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### initialize Pinecone and OpenAI",
   "id": "e43b2b26de0529a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "embed_model = \"text-embedding-3-small\"\n",
    "openai_client = OpenAI()"
   ],
   "id": "30c235882e26ee35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vectorstore = PineconeVectorStore(index_name=os.getenv('PINECONE_INDEX_NAMES'), embedding=embeddings)\n",
    "index_name = os.getenv('PINECONE_INDEX_NAME')\n",
    "namespace = os.getenv('PINECONE_NAMESPACE')\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "# Connect to your Pinecone index\n",
    "pinecone_index = pc.Index(index_name)"
   ],
   "id": "4888c7b1d56f1da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### initialize text splitter",
   "id": "461b6af06fc414e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenizer = tiktoken.get_encoding('p50k_base')\n",
    "\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ],
   "id": "d8658f8a10a1fe02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### get career tips data",
   "id": "4a29afa9c066cc69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load in a YouTube video's transcript\n",
    "urls = [\n",
    "    \"https://wiki.colorstack.org/the-colorstack-family/career-development/career-center/catalinas-corner/resumes\"\n",
    "    \"/bulletpoints\",\n",
    "    \"https://wiki.colorstack.org/the-colorstack-family/career-development/career-center/catalinas-corner/interviews\",\n",
    "    \"https://wiki.colorstack.org/the-colorstack-family/career-development/career-center/catalinas-corner/negotiation\",\n",
    "   \"https://wiki.colorstack.org/the-colorstack-family/career-development/career-center/catalinas-corner/corporate\"\n",
    "   \"-communication\",\n",
    "    \"https://wiki.colorstack.org/the-colorstack-family/career-development/career-center/catalinas-corner/mindset-and\"\n",
    "    \"-time-management\",\n",
    "    \"https://wiki.colorstack.org/the-colorstack-family/career-development/career-center/how-to-speak-to-recruiters\"\n",
    "    \"/linkedin-outreach\",\n",
    "    \"https://wiki.colorstack.org/the-colorstack-family/career-development/career-center/how-to-speak-to-recruiters\"\n",
    "    \"/offer-negotiation\",\n",
    "    \"https://wiki.colorstack.org/the-colorstack-family/career-development/career-center/catalinas-corner/resumes\"\n",
    "    \"/sections-and-orders\",\n",
    "    \"https://wiki.colorstack.org/the-colorstack-family/career-development/career-center/catalinas-corner/resumes/dos\"\n",
    "    \"-and-dont-s\",\n",
    "]\n",
    "\n",
    "loader = WebBaseLoader(urls)\n",
    "data = loader.load()\n",
    "data"
   ],
   "id": "5d67fe57f48d85d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "texts = text_splitter.split_documents(data)\n",
    "texts"
   ],
   "id": "ee3f63332b7ff245",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data -> Pinecone",
   "id": "27441bd1ab856a20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for document in texts:\n",
    "    print(\"\\n\\n\\n\\n----\")\n",
    "\n",
    "    print(document.metadata, document.page_content)\n",
    "\n",
    "    print('\\n\\n\\n\\n----')"
   ],
   "id": "568a3d32ee062b7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vectorstore_from_texts = PineconeVectorStore.from_texts([f\"Source: {t.metadata['source']}, Title: {t\n",
    "                                                        .metadata['title']} \\n\\nContent: {t.page_content}\" for t in \n",
    "                                                         texts], embeddings, index_name=index_name, \n",
    "                                                        namespace=namespace)"
   ],
   "id": "55c4981ac021c9e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Perform RAG",
   "id": "d7c41baa60318298"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "# Connect to your Pinecone index\n",
    "pinecone_index = pc.Index(index_name)"
   ],
   "id": "adc1237fd8bf7a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "query = \"What are some tips for resume building?\"",
   "id": "6e2803488cc2b8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def perform_rag(query):\n",
    "    raw_query_embedding = openai_client.embeddings.create(\n",
    "    input=[query],\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "    query_embedding = raw_query_embedding.data[0].embedding\n",
    "    \n",
    "    top_matches = pinecone_index.query(vector=query_embedding, top_k=10, include_metadata=True, namespace=namespace)\n",
    "\n",
    "    # Get the list of retrieved texts\n",
    "    contexts = [item['metadata']['text'] for item in top_matches['matches']]\n",
    "\n",
    "    augmented_query = \"<CONTEXT>\\n\" + \"\\n\\n-------\\n\\n\".join(contexts[\n",
    "                                                             : 10]) + \"\\n-------\\n</CONTEXT>\\n\\n\\n\\nMY QUESTION:\\n\" + query\n",
    "\n",
    "    # Modify the prompt below as need to improve the response quality\n",
    "    system_prompt = f\"\"\"`You are an AI assistant for a university's Computer Science department. Your role is to help students understand which tech careers are available to them with a Computer Science degree. Here’s how you should interact:\n",
    "  \n",
    "  Overview: Start by explaining the app’s purpose and key features. Show how it can help users grow professionally.\n",
    "  \n",
    "  Information and Guidance: Ask the user if they want to find out about their career options, or if they need help building a resume or cover letter. Help users write their resume and cover letter by asking about their experience and then writing options for bullet points of sentences they can include in their documents.\n",
    "  \n",
    "  Career Advice: Offer tips on becoming more competitive in tech roles, including skill enhancement and industry trends.\n",
    "  \n",
    "  Support and Assistance: Explain best practices for job searching, technical skill development, and submitting applications. Be friendly and encouraging.\n",
    "  \n",
    "  User Engagement: Encourage users to sign up for the waitlist to get early access to a full Computer Science career-readiness dashboard. Users can sign up for the waitlist at https://www.example.com. Keep users engaged by offering to answer questions and provide guidance. Encourage a conversational tone by limiting responses to 7 sentences or less. Use bullet points to break up text and make it easier to read. Limit responses to 10 bullet points or less, each with no more than 90 characters.\n",
    "  \n",
    "  Professional Tone: Keep your responses professional and helpful, ensuring they are actionable and relevant to tech professionals. Don't use special characters.`,\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    res = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": augmented_query}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    for chunk in res:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            yield chunk.choices[0].delta.content\n",
    "\n",
    "    "
   ],
   "id": "82e0c8e5c7bbc931",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "834493243055f4b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
